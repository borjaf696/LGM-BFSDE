{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils.utils import (\n",
    "    ZeroBond,\n",
    "    FinanceUtils\n",
    ")\n",
    "from scripts.trainer.trainer import simulate\n",
    "\n",
    "T = 8\n",
    "\n",
    "T_dicts = {\n",
    "    t: 0 for t in range(1, T)\n",
    "}\n",
    "results_t = {\n",
    "    t: None for t in range(1, T)\n",
    "}\n",
    "# Steps per year\n",
    "nsteps_per_year = 48\n",
    "# Params for check\n",
    "for t in range(1, T):\n",
    "    nsteps = t * nsteps_per_year\n",
    "    # Fixed params\n",
    "    simple_params = {\n",
    "        \"T\": t,\n",
    "        \"N_steps\": nsteps,\n",
    "        \"dim\": 1,\n",
    "        \"sigma\": 0.01,\n",
    "        \"nsims\": 1000\n",
    "    }\n",
    "    data, _ = simulate(\n",
    "        T = simple_params[\"T\"], \n",
    "        N_steps = simple_params[\"N_steps\"], \n",
    "        dim = simple_params[\"dim\"],\n",
    "        sigma = simple_params[\"sigma\"], \n",
    "        nsims = simple_params[\"nsims\"]\n",
    "    )\n",
    "\n",
    "    # Get data to process the ZeroBound\n",
    "    delta_x = data.delta_x_0.values\n",
    "    xt = data.X_0.values\n",
    "    dt = data.dt.values\n",
    "    t_unique = data.dt.unique()\n",
    "    dict_C = {dt:FinanceUtils.C(dt, sigma_value = 0.01) for dt in t_unique}\n",
    "    ct = data.apply(lambda x: dict_C[x['dt']], axis = 1)\n",
    "    nt = ZeroBond.N_tensor(dt,xt,ct)\n",
    "    # Convert to tensors\n",
    "    xt = tf.convert_to_tensor(xt, dtype = tf.float64)\n",
    "    delta_x = tf.convert_to_tensor(delta_x,dtype = tf.float64)\n",
    "    dt = tf.convert_to_tensor(dt, dtype = tf.float64)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    T = tf.Variable(np.float64(T), name = 'T', trainable=False)\n",
    "    # Fix the batch size\n",
    "    batch_size = int(xt.shape[0] / nsteps)\n",
    "    # Real values\n",
    "    v_real = ZeroBond.Z_tensor(xt, dt, T, ct)\n",
    "    v_real_reshaped = tf.reshape(v_real,(batch_size,nsteps))\n",
    "    n_tensor = ZeroBond.N_tensor(dt, xt, ct)\n",
    "    # Derivative:\n",
    "    xt = tf.Variable(xt, name = 'xn', trainable = True)\n",
    "    dt = tf.Variable(dt, name = 'tn', trainable = False)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = ZeroBond.Z_normalized(xt, dt, T, ct)\n",
    "    grad_df = tape.gradient(y, {'xn':xt})\n",
    "    grads = grad_df['xn']\n",
    "    # Simulate - LGM step:\n",
    "    grads_reshaped = tf.reshape(grads, (batch_size, nsteps))\n",
    "    xt_reshaped = tf.reshape(xt, (batch_size, nsteps))\n",
    "    delta_x_reshaped = tf.reshape(delta_x, (batch_size, nsteps))\n",
    "    # Calculate the MVP\n",
    "    v = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "    for i in range(1, nsteps):\n",
    "        v[:, i] = (v[:, i - 1] + grads_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "    # Calculate errors absolute\n",
    "    v_real = np.array(tf.reshape(v_real_reshaped, -1))\n",
    "    v_column = np.array(tf.reshape(v, -1)) * n_tensor.numpy()\n",
    "    dt_list = np.array(dt)\n",
    "    df_results = pd.DataFrame(zip(xt.numpy(), v_real, v_column, dt_list, n_tensor.numpy()), columns = [\"xt\", \"v_real\",\"v_est\",\"dt\", \"n\"])\n",
    "    # Error\n",
    "    df_results[\"absolute_error\"] = (df_results.v_real - df_results.v_est).abs()\n",
    "    # Store results\n",
    "    results_t[t] = df_results.absolute_error.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.00023597587109969338,\n",
       " 2: 0.0003386900836775168,\n",
       " 3: 0.0004269469030297706,\n",
       " 4: 0.0005199961112154946,\n",
       " 5: 0.0006344051798412212,\n",
       " 6: 0.0008010608678608267,\n",
       " 7: 0.0010065686122013705}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils.utils import (\n",
    "    IRS,\n",
    "    ZeroBond,\n",
    "    FinanceUtils\n",
    ")\n",
    "from scripts.trainer.trainer import simulate\n",
    "\n",
    "T = 8\n",
    "\n",
    "T_dicts = {\n",
    "    t: 0 for t in range(1, T)\n",
    "}\n",
    "results_t = {\n",
    "    t: None for t in range(1, T)\n",
    "}\n",
    "# Steps per year\n",
    "nsteps_per_year = 48\n",
    "# Params for check\n",
    "for t in range(1, T):\n",
    "    nsteps = t * nsteps_per_year\n",
    "    # Fixed params\n",
    "    simple_params = {\n",
    "        \"T\": t,\n",
    "        \"N_steps\": nsteps,\n",
    "        \"dim\": 1,\n",
    "        \"sigma\": 0.01,\n",
    "        \"nsims\": 1000\n",
    "    }\n",
    "    data, _ = simulate(\n",
    "        T = simple_params[\"T\"], \n",
    "        N_steps = simple_params[\"N_steps\"], \n",
    "        dim = simple_params[\"dim\"],\n",
    "        sigma = simple_params[\"sigma\"], \n",
    "        nsims = simple_params[\"nsims\"]\n",
    "    )\n",
    "\n",
    "    # Get data to process the ZeroBound\n",
    "    delta_x = data.delta_x_0.values\n",
    "    xt = data.X_0.values\n",
    "    dt = data.dt.values\n",
    "    t_unique = data.dt.unique()\n",
    "    dict_C = {dt:FinanceUtils.C(dt, sigma_value = 0.01) for dt in t_unique}\n",
    "    ct = data.apply(lambda x: dict_C[x['dt']], axis = 1)\n",
    "    nt = ZeroBond.N_tensor(dt,xt,ct)\n",
    "    # Convert to tensors\n",
    "    xt = tf.convert_to_tensor(xt, dtype = tf.float64)\n",
    "    delta_x = tf.convert_to_tensor(delta_x,dtype = tf.float64)\n",
    "    dt = tf.convert_to_tensor(dt, dtype = tf.float64)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    T = tf.Variable(np.float64(T), name = 'T', trainable=False)\n",
    "    # Fix the batch size\n",
    "    batch_size = int(xt.shape[0] / nsteps)\n",
    "    # Real values\n",
    "    v_real = IRS.I(xt, dt, T, ct)\n",
    "    v_real_reshaped = tf.reshape(v_real,(batch_size,nsteps))\n",
    "    n_tensor = ZeroBond.N_tensor(dt, xt, ct)\n",
    "    # Derivative:\n",
    "    xt = tf.Variable(xt, name = 'xn', trainable = True)\n",
    "    dt = tf.Variable(dt, name = 'tn', trainable = False)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = IRS(xt, dt, T, ct)\n",
    "    grad_df = tape.gradient(y, {'xn':xt})\n",
    "    grads = grad_df['xn']\n",
    "    # Simulate - LGM step:\n",
    "    grads_reshaped = tf.reshape(grads, (batch_size, nsteps))\n",
    "    xt_reshaped = tf.reshape(xt, (batch_size, nsteps))\n",
    "    delta_x_reshaped = tf.reshape(delta_x, (batch_size, nsteps))\n",
    "    # Calculate the MVP\n",
    "    v = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "    for i in range(1, nsteps):\n",
    "        v[:, i] = (v[:, i - 1] + grads_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "    # Calculate errors absolute\n",
    "    v_real = np.array(tf.reshape(v_real_reshaped, -1))\n",
    "    v_column = np.array(tf.reshape(v, -1)) * n_tensor.numpy()\n",
    "    dt_list = np.array(dt)\n",
    "    df_results = pd.DataFrame(zip(xt.numpy(), v_real, v_column, dt_list, n_tensor.numpy()), columns = [\"xt\", \"v_real\",\"v_est\",\"dt\", \"n\"])\n",
    "    # Error\n",
    "    df_results[\"absolute_error\"] = (df_results.v_real - df_results.v_est).abs()\n",
    "    # Store results\n",
    "    results_t[t] = df_results.absolute_error.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
