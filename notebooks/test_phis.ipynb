{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils.utils import (\n",
    "    ZeroBond,\n",
    "    FinanceUtils,\n",
    "    VisualizationHelper\n",
    ")\n",
    "from scripts.trainer.trainer import simulate\n",
    "\n",
    "T = 8\n",
    "\n",
    "T_dicts = {\n",
    "    t: 0 for t in range(1, T)\n",
    "}\n",
    "results_t = {\n",
    "    t: None for t in range(1, T)\n",
    "}\n",
    "# Steps per year\n",
    "nsteps_per_year = 48\n",
    "# Params for check\n",
    "for t in range(1, T):\n",
    "    nsteps = t * nsteps_per_year\n",
    "    # Fixed params\n",
    "    simple_params = {\n",
    "        \"T\": t,\n",
    "        \"N_steps\": nsteps,\n",
    "        \"dim\": 1,\n",
    "        \"sigma\": 0.01,\n",
    "        \"nsims\": 1\n",
    "    }\n",
    "    data, _ = simulate(\n",
    "        T = simple_params[\"T\"], \n",
    "        N_steps = simple_params[\"N_steps\"], \n",
    "        dim = simple_params[\"dim\"],\n",
    "        sigma = simple_params[\"sigma\"], \n",
    "        nsims = simple_params[\"nsims\"]\n",
    "    )\n",
    "\n",
    "    # Get data to process the ZeroBound\n",
    "    delta_x = data.delta_x_0.values\n",
    "    xt = data.X_0.values\n",
    "    dt = data.dt.values\n",
    "    t_unique = data.dt.unique()\n",
    "    dict_C = {dt:FinanceUtils.C(dt, sigma_value = 0.01) for dt in t_unique}\n",
    "    ct = data.apply(lambda x: dict_C[x['dt']], axis = 1)\n",
    "    nt = ZeroBond.N_tensor(dt,xt,ct)\n",
    "    # Convert to tensors\n",
    "    xt = tf.convert_to_tensor(xt, dtype = tf.float64)\n",
    "    delta_x = tf.convert_to_tensor(delta_x,dtype = tf.float64)\n",
    "    dt = tf.convert_to_tensor(dt, dtype = tf.float64)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    T = tf.Variable(np.float64(T), name = 'T', trainable=False)\n",
    "    # Fix the batch size\n",
    "    batch_size = int(xt.shape[0] / nsteps)\n",
    "    # Real values\n",
    "    v_real = ZeroBond.Z_tensor(xt, dt, T, ct)\n",
    "    v_real_reshaped = tf.reshape(v_real,(batch_size,nsteps))\n",
    "    n_tensor = ZeroBond.N_tensor(dt, xt, ct)\n",
    "    # Derivative:\n",
    "    xt = tf.Variable(xt, name = 'xn', trainable = True)\n",
    "    dt = tf.Variable(dt, name = 'tn', trainable = False)\n",
    "    ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = ZeroBond.Z_normalized(xt, dt, T, ct)\n",
    "    grad_df = tape.gradient(y, {'xn':xt})\n",
    "    grads = grad_df['xn']\n",
    "    # Simulate - LGM step:\n",
    "    grads_reshaped = tf.reshape(grads, (batch_size, nsteps))\n",
    "    xt_reshaped = tf.reshape(xt, (batch_size, nsteps))\n",
    "    delta_x_reshaped = tf.reshape(delta_x, (batch_size, nsteps))\n",
    "    # Calculate the MVP\n",
    "    v = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "    for i in range(1, nsteps):\n",
    "        v[:, i] = (v[:, i - 1] + grads_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "    # Calculate errors absolute\n",
    "    v_real = np.array(tf.reshape(v_real_reshaped, -1))\n",
    "    v_column = np.array(tf.reshape(v, -1)) * n_tensor.numpy()\n",
    "    dt_list = np.array(dt)\n",
    "    df_results = pd.DataFrame(zip(xt.numpy(), v_real, v_column, dt_list, n_tensor.numpy()), columns = [\"xt\", \"v_real\",\"v_est\",\"dt\", \"n\"])\n",
    "    # Error\n",
    "    df_results[\"absolute_error\"] = (df_results.v_real - df_results.v_est).abs()\n",
    "    # Store results\n",
    "    results_t[t] = df_results.absolute_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizationHelper.plot_multiple_series(df_results, x = \"dt\", values_column = [\"v_real\", \"v_est\"], xlabel=\"dt\")\n",
    "VisualizationHelper.plot_multiple_series(df_results, x = \"xt\", values_column = [\"v_real\", \"v_est\"], xlabel=\"xt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IRS](images/irs/irs.png)\n",
    "$$\n",
    "IRS(t, x_t) = \\mathcal{N}(x_t, t)A_{1,m}(x_t, t, T)\\left(E^{1,m}[S_{i,m}(T_i, T)\\vert F(t)]\\right)\n",
    "$$\n",
    "Donde:\n",
    "* $A_{i,m} = \\tau\\sum_{i}^m P(x_t, T_i, T_m)$, con $\\tau$ constante para todos los pagos en nuestro caso.\n",
    "* $\\mathcal{N}(x_t, t) = \\frac{1}{D(t)}exp(H(t)x_t + \\frac{1}{2}H(t)^2\\zeta(t))$\n",
    "* $P(x_t, t, T) = N(x_t, t) E\\left[ \\frac{1}{N(x_T, T)} \\vert F_t\\right]$\n",
    "\n",
    "En este caso el $E^{i,m}[S_{i,m}(T_i, T)\\vert F(t)]$ es Martingala, entonces la f√≥rmula queda como:\n",
    "$$\n",
    "IRS(t, x_t) = \\mathcal{N}(x_t, t)A_{1,m}(x_t, t, T)\\left(\\frac{P(x_t, t, T_1) - P(x_t, t, T_m)}{A_{1,m}} - K\\right)\n",
    "$$\n",
    "\n",
    "Reference: https://github.com/LechGrzelak/FinancialEngineering_IR_xVA/blob/main/Lecture%2005-Interest%20Rate%20Products/Lecture%2005-Interest%20Rate%20Products.pdf\n",
    "\n",
    "$$\n",
    "IRS(t_0) = (S_{m,n}(t_0) -K)A_{m,n}(t_0)\n",
    "$$\n",
    "with:\n",
    "$$\n",
    "S_{m,n}(t_0) = \\frac{P(t_0, T_m) - P(t_0, T_n)}{A_{m,n}(t_0)}\n",
    "$$\n",
    "$t_0$ is the present time\n",
    "\n",
    "Is $P(t, T_m)$ a Zero-Coupon Bond?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils.utils import (\n",
    "    IRS,\n",
    "    ZeroBond,\n",
    "    FinanceUtils,\n",
    "    VisualizationHelper\n",
    ")\n",
    "from scripts.trainer.trainer import simulate\n",
    "\n",
    "T = 8\n",
    "Tm = 10\n",
    "\n",
    "T_dicts = {\n",
    "    t: 0 for t in range(1, T)\n",
    "}\n",
    "results_t = {\n",
    "    t: None for t in range(1, T)\n",
    "}\n",
    "# Steps per year\n",
    "nsteps_per_year = 48\n",
    "# Params for check\n",
    "nsteps = T * nsteps_per_year\n",
    "# Fixed params\n",
    "simple_params = {\n",
    "    \"T\": T,\n",
    "    \"N_steps\": nsteps,\n",
    "    \"dim\": 1,\n",
    "    \"sigma\": 0.01,\n",
    "    \"nsims\": 1\n",
    "}\n",
    "data, _ = simulate(\n",
    "    T = simple_params[\"T\"], \n",
    "    N_steps = simple_params[\"N_steps\"], \n",
    "    dim = simple_params[\"dim\"],\n",
    "    sigma = simple_params[\"sigma\"], \n",
    "    nsims = simple_params[\"nsims\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to process the ZeroBound\n",
    "delta_x = data.delta_x_0.values\n",
    "xt = data.X_0.values\n",
    "dt = data.dt.values\n",
    "t_unique = data.dt.unique()\n",
    "dict_C = {dt:FinanceUtils.C(dt, sigma_value = 0.01) for dt in t_unique}\n",
    "ct = data.apply(lambda x: dict_C[x['dt']], axis = 1)\n",
    "nt = ZeroBond.N_tensor(dt,xt,ct)\n",
    "# Convert to tensors\n",
    "xt = tf.convert_to_tensor(xt, dtype = tf.float64)\n",
    "delta_x = tf.convert_to_tensor(delta_x,dtype = tf.float64)\n",
    "dt = tf.convert_to_tensor(dt, dtype = tf.float64)\n",
    "ct = tf.convert_to_tensor(ct, dtype = tf.float64)\n",
    "T = tf.convert_to_tensor(T, dtype = tf.float64)\n",
    "Tm = tf.convert_to_tensor(Tm, dtype = tf.float64)\n",
    "# Fix the batch size\n",
    "batch_size = int(xt.shape[0] / nsteps)\n",
    "# Real values\n",
    "v_real = IRS.IRS_test(\n",
    "    xn = xt, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    ")\n",
    "v_real_reshaped = tf.reshape(v_real,(batch_size,nsteps))\n",
    "n_tensor = ZeroBond.N_tensor(dt, xt, ct)\n",
    "# Derivative:\n",
    "xt = tf.Variable(xt, name = 'xn', trainable = True)\n",
    "dt = tf.Variable(dt, name = 'tn', trainable = False)\n",
    "ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "T = tf.Variable(np.float64(T), name = 'T', trainable=False)\n",
    "Tm = tf.Variable(np.float64(Tm), name = 'Tm', trainable=False)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = IRS.IRS_test_normalized(\n",
    "        xn = xt, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    "    )\n",
    "grad_df = tape.gradient(y, {'xn':xt})\n",
    "grads = grad_df['xn']\n",
    "# Custom grads\n",
    "h = 1e-14\n",
    "x_p_h = IRS.IRS_test_normalized(\n",
    "    xn = xt + h, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    ")\n",
    "x_m_h = IRS.IRS_test_normalized(\n",
    "    xn = xt - h, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    ")\n",
    "grad_custom = (x_p_h - x_m_h)/(2 * h)\n",
    "# Simulate - LGM step:\n",
    "grads_reshaped = tf.reshape(grads, (batch_size, nsteps))\n",
    "grad_custom_reshaped = tf.reshape(grad_custom, (batch_size, nsteps))\n",
    "n_tensor_reshaped = tf.reshape(n_tensor, (batch_size, nsteps))\n",
    "xt_reshaped = tf.reshape(xt, (batch_size, nsteps))\n",
    "delta_x_reshaped = tf.reshape(delta_x, (batch_size, nsteps))\n",
    "# Calculate the MVP\n",
    "v = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "v_custom = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "for i in range(1, nsteps):\n",
    "    v[:, i] = (v[:, i - 1] + grads_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "    v_custom[:, i] = (v_custom[:, i - 1] + grad_custom_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "# Calculate errors absolute\n",
    "v_real = np.array(tf.reshape(v_real_reshaped, -1))\n",
    "v_column = np.array(tf.reshape(v, -1)) * n_tensor.numpy()\n",
    "v_custom = np.array(tf.reshape(v_custom, -1)) * n_tensor.numpy()\n",
    "dt_list = np.array(dt)\n",
    "df_results = pd.DataFrame(\n",
    "    zip(xt.numpy(), v_real, v_column, v_custom, dt_list, n_tensor.numpy(), grads.numpy(), grad_custom.numpy()), \n",
    "    columns = [\"xt\", \"v_real\",\"v_est\",\"v_est_custom\",\"dt\", \"n\", \"grads\", \"grads_custom\"])\n",
    "# Error\n",
    "df_results[\"absolute_error\"] = (df_results.v_real - df_results.v_est).abs()\n",
    "# Store results\n",
    "results_t[int(T)] = df_results.absolute_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizationHelper.plot_multiple_series(df_results, x = \"dt\", values_column = [\"v_real\", \"v_est\", \"v_est_custom\"], xlabel=\"dt\")\n",
    "VisualizationHelper.plot_multiple_series(df_results, x = \"xt\", values_column = [\"v_real\", \"v_est\", \"v_est_custom\"], xlabel=\"xt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swaption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils.utils import (\n",
    "    ZeroBond,\n",
    "    Swaption,\n",
    "    FinanceUtils,\n",
    "    VisualizationHelper\n",
    ")\n",
    "from scripts.trainer.trainer import simulate\n",
    "\n",
    "T = 8\n",
    "Tm = 10\n",
    "\n",
    "T_dicts = {\n",
    "    t: 0 for t in range(1, T)\n",
    "}\n",
    "results_t = {\n",
    "    t: None for t in range(1, T)\n",
    "}\n",
    "# Steps per year\n",
    "nsteps_per_year = 48\n",
    "# Params for check\n",
    "nsteps = T * nsteps_per_year\n",
    "# Fixed params\n",
    "simple_params = {\n",
    "    \"T\": T,\n",
    "    \"N_steps\": nsteps,\n",
    "    \"dim\": 1,\n",
    "    \"sigma\": 0.01,\n",
    "    \"nsims\": 1\n",
    "}\n",
    "data, _ = simulate(\n",
    "    T = simple_params[\"T\"], \n",
    "    N_steps = simple_params[\"N_steps\"], \n",
    "    dim = simple_params[\"dim\"],\n",
    "    sigma = simple_params[\"sigma\"], \n",
    "    nsims = simple_params[\"nsims\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to process the ZeroBound\n",
    "delta_x = data.delta_x_0.values\n",
    "xt = data.X_0.values\n",
    "dt = data.dt.values\n",
    "t_unique = data.dt.unique()\n",
    "dict_C = {dt:FinanceUtils.C(dt, sigma_value = 0.01) for dt in t_unique}\n",
    "ct = data.apply(lambda x: dict_C[x['dt']], axis = 1)\n",
    "nt = ZeroBond.N_tensor(dt,xt,ct)\n",
    "# Convert to tensors\n",
    "xt = tf.convert_to_tensor(xt, dtype = tf.float64)\n",
    "delta_x = tf.convert_to_tensor(delta_x,dtype = tf.float64)\n",
    "dt = tf.convert_to_tensor(dt, dtype = tf.float64)\n",
    "ct = tf.convert_to_tensor(ct, dtype = tf.float64)\n",
    "T = tf.convert_to_tensor(T, dtype = tf.float64)\n",
    "Tm = tf.convert_to_tensor(Tm, dtype = tf.float64)\n",
    "# Fix the batch size\n",
    "batch_size = int(xt.shape[0] / nsteps)\n",
    "# Real values\n",
    "v_real = Swaption.Swaption_test(\n",
    "    xn = xt, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    ")\n",
    "v_real_reshaped = tf.reshape(v_real,(batch_size,nsteps))\n",
    "n_tensor = ZeroBond.N_tensor(dt, xt, ct)\n",
    "# Derivative:\n",
    "xt = tf.Variable(xt, name = 'xn', trainable = True)\n",
    "dt = tf.Variable(dt, name = 'tn', trainable = False)\n",
    "ct = tf.Variable(np.float64(ct), name = 'ct', trainable=False)\n",
    "T = tf.Variable(np.float64(T), name = 'T', trainable=False)\n",
    "Tm = tf.Variable(np.float64(Tm), name = 'Tm', trainable=False)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = Swaption.Swaption_test_normalized(\n",
    "        xn = xt, t = dt, Ti = T, Tm = Tm, ct = ct\n",
    "    )\n",
    "grad_df = tape.gradient(y, {'xn':xt})\n",
    "grads = grad_df['xn']\n",
    "# Simulate - LGM step:\n",
    "grads_reshaped = tf.reshape(grads, (batch_size, nsteps))\n",
    "xt_reshaped = tf.reshape(xt, (batch_size, nsteps))\n",
    "delta_x_reshaped = tf.reshape(delta_x, (batch_size, nsteps))\n",
    "# Calculate the MVP\n",
    "v = np.ones((batch_size, nsteps)) * np.float64(v_real_reshaped[0, 0])\n",
    "for i in range(1, nsteps):\n",
    "    v[:, i] = (v[:, i - 1] + grads_reshaped[:, i - 1] * delta_x_reshaped[:, i])\n",
    "# Calculate errors absolute\n",
    "v_real = np.array(tf.reshape(v_real_reshaped, -1))\n",
    "v_column = np.array(tf.reshape(v, -1)) * n_tensor.numpy()\n",
    "dt_list = np.array(dt)\n",
    "df_results = pd.DataFrame(\n",
    "    zip(xt.numpy(), v_real, v_column, dt_list, n_tensor.numpy(), grads.numpy()), \n",
    "    columns = [\"xt\", \"v_real\",\"v_est\",\"dt\", \"n\", \"grads\"])\n",
    "# Error\n",
    "df_results[\"absolute_error\"] = (df_results.v_real - df_results.v_est).abs()\n",
    "# Store results\n",
    "results_t[int(T)] = df_results.absolute_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizationHelper.plot_multiple_series(df_results, x = \"dt\", values_column = [\"v_real\", \"v_est\"], xlabel=\"dt\")\n",
    "VisualizationHelper.plot_multiple_series(df_results, x = \"xt\", values_column = [\"v_real\", \"v_est\"], xlabel=\"xt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
