{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 02:50:59.874370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Custom utils\n",
    "from utils.simulator.simulator import MCSimulation\n",
    "# Tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_derivative_model(x, model, multioutput = True, mode = 'centered'):\n",
    "    h = 1e-1\n",
    "    # Size x\n",
    "    x_dim, y_dim = x.shape\n",
    "    # Gradient vector\n",
    "    if multioutput:\n",
    "        gradient = np.zeros((x_dim, y_dim, y_dim))\n",
    "    else:\n",
    "        gradient = np.zeros((x_dim, y_dim, 1))\n",
    "    for i in range(y_dim):\n",
    "        # Vector for partial derivative estimation\n",
    "        offset_tensor = np.zeros((x_dim, y_dim))\n",
    "        offset_tensor[:, i] = h\n",
    "        offset_tensor = tf.convert_to_tensor(offset_tensor,\n",
    "                                             dtype = tf.float32)\n",
    "        # Constantes:\n",
    "        denominator = h\n",
    "        if mode == 'progressive':\n",
    "            numerator = model(\n",
    "                tf.math.add(x, offset_tensor)\n",
    "            ) - model(\n",
    "                x\n",
    "            ) \n",
    "        elif mode == 'regressive':\n",
    "            numerator = model(\n",
    "                x\n",
    "            ) - model(\n",
    "                tf.math.subtract(x, offset_tensor)\n",
    "            )\n",
    "        elif mode == 'centered':\n",
    "            numerator = tf.math.subtract(\n",
    "                model(\n",
    "                    tf.math.add(x, offset_tensor)\n",
    "                ), model(\n",
    "                    tf.math.subtract(x, offset_tensor)\n",
    "                )\n",
    "            )\n",
    "        denominator = 2 * h\n",
    "        gradient [:, i, :] = numerator / denominator\n",
    "    gradient = tf.convert_to_tensor(gradient,\n",
    "                                        dtype = tf.float32)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 02:51:21.888769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.Input(shape = (2,), name='input_nn')\n",
    "output_layer = layers.Dense(\n",
    "    units = 1, \n",
    "    activation = 'relu', \n",
    "    name = 'first_dense'\n",
    ")(input_layer)\n",
    "custom_model = keras.Model(\n",
    "    inputs=[input_layer],\n",
    "    outputs=[output_layer],\n",
    "    name = 'test_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain -5:5\n",
    "x = tf.convert_to_tensor(\n",
    "    np.array(range(0,20)).reshape((10,2)),\n",
    "    dtype = tf.float32    \n",
    ")\n",
    "# Test \n",
    "xs = tf.Variable(x, trainable = True, name = 'x')\n",
    "with tf.GradientTape() as tape, tf.GradientTape() as tape_2:\n",
    "    tape.watch(xs)\n",
    "    tape_2.watch(xs)\n",
    "    y = custom_model(xs)\n",
    "# This represents dV/dX\n",
    "grads = tape.gradient(y, {\n",
    "    'x':xs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_grads = custom_derivative_model(x, custom_model, multioutput=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2, 1), dtype=float32, numpy=\n",
       "array([[[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.1179982 ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.9054357 ],\n",
       "        [-0.06694436]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.       , -0.       ],\n",
       "        [ 0.9054364, -0.066944 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b391e97e35ec4987120a2f780cd64183fdb56c026e5a7e01d3347b3d6528b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
