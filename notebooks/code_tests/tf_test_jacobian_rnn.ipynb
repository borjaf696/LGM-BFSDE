{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:07:51.009748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Custom utils\n",
    "from utils.simulator.simulator import MCSimulation\n",
    "# Tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_derivative_model(x, model, multioutput = True, mode = 'centered'):\n",
    "    h = 1e-1\n",
    "    # Size x\n",
    "    x_dim, y_dim, _ = x.shape\n",
    "    # Gradient vector\n",
    "    if multioutput:\n",
    "        gradient = np.zeros((x_dim, y_dim, 1))\n",
    "    else:\n",
    "        gradient = np.zeros((x_dim, y_dim))\n",
    "    for i in range(y_dim):\n",
    "        # Vector for partial derivative estimation\n",
    "        offset_tensor = np.zeros((x_dim, y_dim, 1))\n",
    "        offset_tensor[:, i] = h\n",
    "        offset_tensor = tf.convert_to_tensor(offset_tensor,\n",
    "                                             dtype = tf.float32)\n",
    "        # Constantes:\n",
    "        denominator = h\n",
    "        if mode == 'progressive':\n",
    "            numerator = model(\n",
    "                tf.math.add(x, offset_tensor)\n",
    "            ) - model(\n",
    "                x\n",
    "            ) \n",
    "        elif mode == 'regressive':\n",
    "            numerator = model(\n",
    "                x\n",
    "            ) - model(\n",
    "                tf.math.subtract(x, offset_tensor)\n",
    "            )\n",
    "        elif mode == 'centered':\n",
    "            numerator = tf.math.subtract(\n",
    "                model(\n",
    "                    tf.math.add(x, offset_tensor)\n",
    "                ), model(\n",
    "                    tf.math.subtract(x, offset_tensor)\n",
    "                )\n",
    "            )\n",
    "        denominator = 2 * h\n",
    "        print(f'Numerator: {numerator}')\n",
    "        print(f'Denominator: {denominator}')\n",
    "        gradient [:, i, :] = numerator / denominator\n",
    "    gradient = tf.convert_to_tensor(gradient,\n",
    "                                        dtype = tf.float32)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape = (10, 1), name='input_nn')\n",
    "output_layer = layers.GRU(1, \n",
    "                dropout = 0.0,\n",
    "                input_shape = (10, 1),\n",
    "                return_sequences = True,\n",
    "                name = 'sequential_layer')(input_layer)\n",
    "custom_model = keras.Model(\n",
    "    inputs=[input_layer],\n",
    "    outputs=[output_layer],\n",
    "    name = 'test_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.032103776931762695\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(\n",
    "    np.array(range(0,30)).reshape((3,10, 1)),\n",
    "    dtype = tf.float32    \n",
    ")\n",
    "# Test \n",
    "import time\n",
    "tf_start = time.time()\n",
    "xs = tf.Variable(x, trainable = True, name = 'x')\n",
    "with tf.GradientTape() as tape, tf.GradientTape() as tape_2:\n",
    "    tape.watch(xs)\n",
    "    tape_2.watch(xs)\n",
    "    y = custom_model(xs)\n",
    "tf_end = time.time()\n",
    "print(f'Execution time: {tf_end - tf_start}')\n",
    "# This represents dV/dX\n",
    "grads = tape.gradient(y, {\n",
    "    'x':xs\n",
    "})\n",
    "jacobian = tape_2.jacobian(y, {\n",
    "    'x':xs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <tf.Tensor: shape=(3, 10, 1), dtype=float32, numpy=\n",
       " array([[[ 3.18759531e-01],\n",
       "         [ 2.56062269e-01],\n",
       "         [ 1.87381893e-01],\n",
       "         [ 1.20098025e-01],\n",
       "         [ 6.42444417e-02],\n",
       "         [ 2.52150819e-02],\n",
       "         [ 2.90626287e-03],\n",
       "         [-6.33487664e-03],\n",
       "         [-7.30305910e-03],\n",
       "         [-4.22189571e-03]],\n",
       " \n",
       "        [[-1.55025691e-01],\n",
       "         [-1.14448510e-01],\n",
       "         [-8.25277418e-02],\n",
       "         [-5.80778755e-02],\n",
       "         [-3.97756360e-02],\n",
       "         [-2.63540596e-02],\n",
       "         [-1.67015865e-02],\n",
       "         [-9.89617221e-03],\n",
       "         [-5.20195952e-03],\n",
       "         [-2.04787776e-03]],\n",
       " \n",
       "        [[-1.86392535e-02],\n",
       "         [-1.32019781e-02],\n",
       "         [-9.22937598e-03],\n",
       "         [-6.34808186e-03],\n",
       "         [-4.27555619e-03],\n",
       "         [-2.79885833e-03],\n",
       "         [-1.75850012e-03],\n",
       "         [-1.03559194e-03],\n",
       "         [-5.42031135e-04],\n",
       "         [-2.12762054e-04]]], dtype=float32)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerator: [[[ 0.021808  ]\n",
      "  [ 0.01288341]\n",
      "  [ 0.00839078]\n",
      "  [ 0.00581023]\n",
      "  [ 0.00420725]\n",
      "  [ 0.00316256]\n",
      "  [ 0.00246066]\n",
      "  [ 0.00197893]\n",
      "  [ 0.00164258]\n",
      "  [ 0.00140393]]\n",
      "\n",
      " [[-0.00335634]\n",
      "  [-0.00327525]\n",
      "  [-0.00320315]\n",
      "  [-0.00314112]\n",
      "  [-0.00308898]\n",
      "  [-0.00304592]\n",
      "  [-0.00301072]\n",
      "  [-0.00298235]\n",
      "  [-0.00295955]\n",
      "  [-0.00294137]]\n",
      "\n",
      " [[-0.00037433]\n",
      "  [-0.00037374]\n",
      "  [-0.00037333]\n",
      "  [-0.00037301]\n",
      "  [-0.0003727 ]\n",
      "  [-0.00037251]\n",
      "  [-0.00037234]\n",
      "  [-0.00037219]\n",
      "  [-0.00037205]\n",
      "  [-0.00037195]]]\n",
      "Denominator: 0.2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,10,1) into shape (3,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m custom_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m custom_grads \u001b[39m=\u001b[39m custom_derivative_model(x, custom_model)\n\u001b[1;32m      3\u001b[0m custom_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExecution time custom: \u001b[39m\u001b[39m{\u001b[39;00mcustom_end\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mcustom_start\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m, in \u001b[0;36mcustom_derivative_model\u001b[0;34m(x, model, multioutput, mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumerator: \u001b[39m\u001b[39m{\u001b[39;00mnumerator\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDenominator: \u001b[39m\u001b[39m{\u001b[39;00mdenominator\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     gradient [:, i, :] \u001b[39m=\u001b[39m numerator \u001b[39m/\u001b[39m denominator\n\u001b[1;32m     42\u001b[0m gradient \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(gradient,\n\u001b[1;32m     43\u001b[0m                                     dtype \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m gradient\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,10,1) into shape (3,1)"
     ]
    }
   ],
   "source": [
    "custom_start = time.time()\n",
    "custom_grads = custom_derivative_model(x, custom_model)\n",
    "custom_end = time.time()\n",
    "print(f'Execution time custom: {custom_end - custom_start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b391e97e35ec4987120a2f780cd64183fdb56c026e5a7e01d3347b3d6528b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
