{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward basic\n",
    "\n",
    "Basic equation with just one layer:\n",
    "\n",
    "$$NN(X) = f( W\\cdot X + b)$$\n",
    "with $f(\\cdot)$ a ReLU function:\n",
    "$$\n",
    "f(x) = \\begin{cases}\n",
    "    0, & \\text{if } x < 0\\\\\n",
    "    x, & \\text{if } x \\geq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "and $W$ is a matrix of weights per neuron in the layer with dimension $(|N|_{n+1} \\times |N|_n)$\n",
    "Derivative given the entry:\n",
    "$$\n",
    "\\frac{dNN_j(X)}{dX_i} = \\frac{dNN_j}{df}\\frac{df}{dX_i} = \n",
    "\\begin{cases}\n",
    "    0, & \\text{if } x < 0\\\\\n",
    "    W_{ji}, & \\text{if } x \\geq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "* Given a neural network with 1 layer and 2 neurons in the layer we have:\n",
    "$$\n",
    "W = \\begin{bmatrix}\n",
    "    1 & 2 & 3\\\\\n",
    "    3 & 4 & 6\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    3 \n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    2 \\\\\n",
    "    3\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 10:20:05.870044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Custom utils\n",
    "from utils.simulator.simulator import MCSimulation\n",
    "# Tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        X (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return tf.keras.activations.relu(X).numpy()\n",
    "\n",
    "def relu_derivative(X, partial_x = 0, partial_j = 0):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        X (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return X[partial_j][partial_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape = (2,), name='input_nn')\n",
    "dense_unit = layers.Dense(\n",
    "    units = 2,\n",
    "    activation = 'relu',\n",
    "    name = 'dense_layer'\n",
    ")(input_layer)\n",
    "custom_model = keras.Model(\n",
    "    inputs=[input_layer],\n",
    "    outputs=[dense_unit],\n",
    "    name = 'test_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los pesos de la capa oculta\n",
    "w = custom_model.get_layer('dense_layer').get_weights()[0].T\n",
    "b = custom_model.get_layer('dense_layer').get_weights()[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(\n",
    "    np.array(range(-7,-1)).reshape((2,3)),\n",
    "    dtype = tf.float32    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_result = tf.transpose(relu(tf.matmul(w, x)))\n",
    "model_output = custom_model(tf.transpose(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[0.       , 1.5790672],\n",
       "        [0.       , 1.7795793],\n",
       "        [0.       , 1.9800918]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[0.       , 1.5790672],\n",
       "        [0.       , 1.7795793],\n",
       "        [0.       , 1.9800918]], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_result, model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "xs = tf.Variable(x, trainable = False, name = 'x')\n",
    "with tf.GradientTape() as tape, tf.GradientTape() as tape_2:\n",
    "    tape.watch(xs)\n",
    "    tape_2.watch(xs)\n",
    "    y = custom_model(tf.transpose(xs))\n",
    "# This represents dV/dX\n",
    "grads = tape.gradient(y, {\n",
    "    'x':xs\n",
    "})\n",
    "jacobian = tape_2.jacobian(y, {\n",
    "    'x':xs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-0.79370534, -0.79370534, -0.79370534],\n",
       "       [ 0.9942175 ,  0.9942175 ,  0.9942175 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
       " array([[[ 0.        ,  0.        ],\n",
       "         [-0.79370534,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.9942175 ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2, 2, 3), dtype=float32, numpy=\n",
       " array([[[[ 0.        ,  0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "         [[-0.79370534,  0.        ,  0.        ],\n",
       "          [ 0.9942175 ,  0.        ,  0.        ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.        ,  0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        , -0.79370534,  0.        ],\n",
       "          [ 0.        ,  0.9942175 ,  0.        ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.        ,  0.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.        ,  0.        , -0.79370534],\n",
       "          [ 0.        ,  0.        ,  0.9942175 ]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.diag_part(jacobian['x']),jacobian['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_grads = np.zeros((\n",
    "    2,4\n",
    "))\n",
    "for j in range(2):\n",
    "    for i in range(4):\n",
    "        custom_grads[j,i] = relu_derivative(w, partial_x = i, partial_j = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55118585, -0.1299386 , -0.6776278 , -0.80925226],\n",
       "       [-0.80925632, -0.00675702, -0.05111217, -0.39438462]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([16 16 49], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir dos tensores\n",
    "A = tf.constant([5, 3, 2])\n",
    "B = tf.constant([1, 7, 9])\n",
    "\n",
    "# Calcular el cuadrado de la diferencia entre los tensores\n",
    "C = tf.math.squared_difference(A, B)\n",
    "\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x1': <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[ 4.,  6.],\n",
      "       [10., 16.]], dtype=float32)>, 'x2': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([20., 32.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1 = tf.Variable([[2.0, 3.0], [5, 8]], name = 'x1')\n",
    "x2 = tf.constant([5.0, 8.0], name = 'x2')\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x1)\n",
    "    t.watch(x2)\n",
    "    y = tf.math.add(tf.square(x1), tf.square(x2))\n",
    "\n",
    "jacobian = t.gradient(y, {\n",
    "    'x1':x1,\n",
    "    'x2':x2\n",
    "})\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b391e97e35ec4987120a2f780cd64183fdb56c026e5a7e01d3347b3d6528b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
