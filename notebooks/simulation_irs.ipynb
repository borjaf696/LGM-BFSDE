{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first trial we assume a naive model (LGM) defined as:\n",
    "$$dx_t = \\sigma_t dW_t^{\\mathit{N}}$$\n",
    "\n",
    "Let's define the Numeraire as:\n",
    "$$N(t, x_t) = \\frac{1}{B(0,t)}exp^{H_tx_t + \\frac{1}{2}H_t^2\\zeta_t}$$\n",
    "where $H_t$ and $\\zeta_t$ are known functions.\n",
    "\n",
    "With this let's defined the fundamental equation for the pricing of a derivative under the model. The NPV (Net Present Value) is:\n",
    "$$V_t = V(t, x_t)$$ \n",
    "and the deflated version \n",
    "$$\\overline{V}_t = V(t, x_t) / N(t, x_t)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Montecarlo simulation\n",
    "\n",
    "* Brownian path:\n",
    "$$W_t \\sim \\mathcal{N}(0,t)$$\n",
    "$$W[0] = X_0$$\n",
    "$$W[t] = W[t - 1]  + \\mathcal{Z} \\cdot \\Delta t^{\\frac{1}{2}}$$\n",
    "with \n",
    "$$\\mathcal{Z} \\sim \\mathcal{N}(0,1)$$\n",
    "* X:\n",
    "$$X_{t + 1} = X_t + \\sigma \\cdot (W_{t + 1} - W_t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.simulator.simulator import MCSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strike value\n",
    "Vt = 2\n",
    "T = 4\n",
    "# Set of parameters\n",
    "T, N_steps, X0, sigma = (T, 100, 0, 0.01)\n",
    "mcsimulator = MCSimulation(T, N_steps, X0, sigma)\n",
    "nsims = int(1e3)\n",
    "test_sims = int(nsims * 0.2)\n",
    "# Training\n",
    "mc_paths, W = mcsimulator.simulate(nsims)\n",
    "mc_paths_transpose = mc_paths.T\n",
    "mc_paths_flatten = mc_paths.flatten('C')\n",
    "w_paths_flatten = W.flatten('C')\n",
    "# Test\n",
    "mc_paths_test, W_test = mcsimulator.simulate(test_sims)\n",
    "mc_paths_test_transpose = mc_paths_test.T\n",
    "mc_paths_test_flatten = mc_paths_test.flatten('C')\n",
    "w_paths_test_flatten = W_test.flatten('C')\n",
    "# Deltas\n",
    "deltaTs = np.linspace(0, T, N_steps)\n",
    "simulations = np.linspace(0, nsims - 1, nsims)\n",
    "simulations = np.int32(np.tile(simulations, N_steps))\n",
    "deltaTs = np.tile(deltaTs.reshape(N_steps, 1), nsims).flatten()\n",
    "df_x = pd.DataFrame(zip(\n",
    "    deltaTs,\n",
    "    mc_paths_flatten,\n",
    "    w_paths_flatten,\n",
    "    simulations\n",
    "), columns = ['dt',\n",
    "              'xt',\n",
    "              'wt',\n",
    "              'simulation'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTs = np.linspace(0, T, N_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "if nsims < 101:\n",
    "    plt.figure(figsize = (15,6))\n",
    "    plt.title('Complete set of paths')\n",
    "    sns.lineplot(x = 'dt', y = 'xt', hue = 'simulation', data = df_x)\n",
    "    plt.show()\n",
    "    plt.figure(figsize = (15,6))\n",
    "    plt.title('Complete paths distribution')\n",
    "    sns.regplot(x = 'dt', y = 'xt', data = df_x, scatter = False)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests with IRS\n",
    "\n",
    "An IRS, interes rate swap, is a swap between two institutions that decide to interchange interest rates. One of the pays a fixed part while the other pays a variable part. The final objective is allow the two parts, institutions, to be safe against risky fluctuations in interest rates.\n",
    "\n",
    "As starting point let's remember two basic concepts:\n",
    "* Numeraire, or take to zero the option, IRS or one particular value.\n",
    "* Zero Bond coupon, the most basic coupon, it pays one at strike time.\n",
    "\n",
    "Numeraire: \n",
    "\n",
    "$$N(t, x_t) = \\frac{1}{D(t)}exp^{H_tx_t + \\frac{1}{2}H_t^2\\zeta_t}$$\n",
    "where:\n",
    "* $D(t)$ discount factor and can be calculated as $D(t) = e^{-rt}$, in the examples ahead we stick to a $r = 0.03$\n",
    "* $H(t) = \\frac{1 - e^{-\\kappa t}}{\\kappa}$, with $\\kappa = 2$\n",
    "\n",
    "Zero Bond coupon:\n",
    "\n",
    "$$Z(x_t, t, T) = D(T)exp(-\\frac{1}{2}H_T^2\\zeta_t-H_Tx_t)N(t, x_t)$$\n",
    "where:\n",
    "* $\\zeta(t) = \\int_0^t\\sigma^2(s)ds$, with $\\sigma(s)$ a piecewise function.\n",
    "\n",
    "From here we can develop the equation that defines an IRS, interest rate swap.\n",
    "\n",
    "$$V(T) = 1 - Z(x_T, T, T_N) - \\mathcal{T} \\sum_{i = 1}^n \\tau_i Z(x_T, T, T_i)$$\n",
    "\n",
    "where:\n",
    "* $1 - Z(x_T, T, T_N)$ is the variable part of the IRS.\n",
    "* $\\mathcal{T} \\sum_{i = 1}^n \\tau_i Z(x_T, T, T_i)$ defines the fixed part of the IRS.\n",
    "* $\\mathcal{T}$ is the fixed interest rate.\n",
    "* $\\tau_i$ represents the fraction of the fixed part of the IRS that is paid at the time $T_i$.\n",
    "\n",
    "From here we can easily derivate the IRS Swaption as:\n",
    "$$V(T) = max(\\phi(1 - Z(x_T, T, T_N) - \\mathcal{T} \\sum_{i = 1}^n \\tau_i Z(x_T, T, T_i)), 0 )$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward neural networks\n",
    "\n",
    "The next sections aims to build the technical part of the project:\n",
    "* Neural network architecture\n",
    "* Evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.clear_session() \n",
    "keras.backend.set_floatx('float64')\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils.utils import MLUtils\n",
    "dts = list(np.linspace(0, T, N_steps)) * len(mc_paths_transpose)\n",
    "simulation = [\n",
    "    [i] * N_steps for i in range(nsims)\n",
    "]\n",
    "df_x_tmp = pd.DataFrame(\n",
    "    zip(\n",
    "        mc_paths_transpose,\n",
    "        simulation\n",
    "    ),\n",
    "    columns = [\n",
    "        'path',\n",
    "        'simulation'\n",
    "    ]\n",
    ")\n",
    "df_x = pd.DataFrame()\n",
    "df_x['xt'] = df_x_tmp.explode('path')['path']\n",
    "df_x['dt'] = dts\n",
    "df_x['simulation'] = df_x_tmp.explode('simulation')['simulation']\n",
    "df_x['_delta_x'] = df_x.groupby([\n",
    "    'simulation',\n",
    "])['xt'].shift(1)\n",
    "df_x['_delta_x'] = (df_x['xt'] - df_x['_delta_x'])\n",
    "df_x.loc[df_x._delta_x.isna(), '_delta_x'] = 0.\n",
    "# Sort to get the examples in blocks\n",
    "df_x.sort_values(\n",
    "    [\n",
    "        'simulation',\n",
    "        'dt'\n",
    "    ],\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (100000, 2)\n",
      "Batch size: 100 paths per epoch with length 100\n",
      "T: 4\n",
      "Positions to avoid from V 100.0\n",
      "Positions to complete from V 100.0\n",
      "Model: \"swaption\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_nn (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " internal_relu_dense_0 (Dens  (None, 32)               96        \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_1 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_2 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_3 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_4 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_5 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_6 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_7 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_8 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_9 (Dens  (None, 32)               1056      \n",
      " e)                                                              \n",
      "                                                                 \n",
      " internal_relu_dense_10 (Den  (None, 32)               1056      \n",
      " se)                                                             \n",
      "                                                                 \n",
      " internal_relu_dense_11 (Den  (None, 32)               1056      \n",
      " se)                                                             \n",
      "                                                                 \n",
      " output_relu_dense (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,745\n",
      "Trainable params: 11,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Optimizer set to adam\n",
      "0..."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from model.model_lgm_single_step import LGM_model_one_step\n",
    "from utils.utils.utils import IRS, Swaption\n",
    "\n",
    "epochs = 50\n",
    "mc_paths_tranformed = df_x[['xt', 'dt']].values\n",
    "# Data used as features\n",
    "x = mc_paths_tranformed.astype(np.float64)\n",
    "delta_x = df_x._delta_x.values.astype(np.float64)\n",
    "print(f'Features shape: {x.shape}')\n",
    "# Batch execution with baby steps\n",
    "size_of_the_batch = 100\n",
    "batch_size = size_of_the_batch * N_steps\n",
    "batches = int(np.floor(nsims * N_steps / batch_size))\n",
    "print(f'Batch size: {size_of_the_batch} paths per epoch with length {N_steps}')\n",
    "# Custom model\n",
    "lgm_single_step = LGM_model_one_step(n_steps = N_steps, \n",
    "                                     T = T, \n",
    "                                     future_T = 2 * T,\n",
    "                                     verbose = False,\n",
    "                                     sigma = sigma,\n",
    "                                     batch_size = size_of_the_batch,\n",
    "                                     phi = IRS.IRS_normalized,\n",
    "                                     name = 'irs'\n",
    ")\n",
    "print(f'{lgm_single_step.summary()}')\n",
    "# Compile the model\n",
    "lgm_single_step.define_compiler(optimizer = 'adam', learning_rate = 1e-3)\n",
    "# Losses:\n",
    "losses_split = {\n",
    "    'total': [],\n",
    "    'strike_loss': [],\n",
    "    'strike_derivative_loss': [],\n",
    "    'steps_error': []\n",
    "}\n",
    "# Custom iteration: \n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(f'{epoch}...', end = '')\n",
    "    dimension = (1, batches)\n",
    "    total_tmp, strike_tmp, derivative_tmp, steps_tmp = (\n",
    "        np.zeros(dimension),\n",
    "        np.zeros(dimension),\n",
    "        np.zeros(dimension),\n",
    "        np.zeros(dimension)\n",
    "    )\n",
    "    for batch in range(batches):\n",
    "        x_batch = x[batch * batch_size: (batch + 1) * batch_size, :]\n",
    "        delta_x_batch = delta_x[batch * batch_size: (batch + 1) * batch_size]\n",
    "        el, sl, sdl, se = lgm_single_step.custom_train_step(\n",
    "            X = x_batch,\n",
    "            batch = batch,\n",
    "            epoch = epoch, \n",
    "            start_time = start_time,\n",
    "            delta_x = delta_x_batch)\n",
    "        # Store partial results\n",
    "        total_tmp[0, batch] = el\n",
    "        strike_tmp[0, batch] = sl\n",
    "        derivative_tmp[0, batch] = sdl\n",
    "        steps_tmp[0, batch] = se\n",
    "    losses_split['total'].append(\n",
    "        el\n",
    "    )\n",
    "    losses_split['strike_loss'].append(\n",
    "        sl\n",
    "    )\n",
    "    losses_split['strike_derivative_loss'].append(\n",
    "        sdl\n",
    "    )\n",
    "    losses_split['steps_error'].append(\n",
    "        se\n",
    "    )\n",
    "# Visualize errors\n",
    "plt.figure()\n",
    "sns.lineplot(x = [i for i in range(epochs)], \n",
    "             y = losses_split['total'], \n",
    "             color = 'blue')\n",
    "sns.lineplot(x = [i for i in range(epochs)], \n",
    "             y = losses_split['strike_loss'],\n",
    "             color = 'red')\n",
    "sns.lineplot(x = [i for i in range(epochs)], \n",
    "             y = losses_split['strike_derivative_loss'],\n",
    "             color = 'orange')\n",
    "sns.lineplot(x = [i for i in range(epochs)], \n",
    "             y = losses_split['steps_error'],\n",
    "             color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = list(np.linspace(0, T, N_steps)) * len(mc_paths_test_transpose)\n",
    "simulation = [\n",
    "    [i] * N_steps for i in range(test_sims)\n",
    "]\n",
    "df_x_tmp = pd.DataFrame(\n",
    "    zip(\n",
    "        mc_paths_test_transpose,\n",
    "        simulation\n",
    "    ),\n",
    "    columns = [\n",
    "        'path',\n",
    "        'simulation'\n",
    "    ]\n",
    ")\n",
    "df_x = pd.DataFrame()\n",
    "df_x['xt'] = df_x_tmp.explode('path')['path']\n",
    "df_x['dt'] = dts\n",
    "df_x['simulation'] = df_x_tmp.explode('simulation')['simulation']\n",
    "df_x['_delta_x'] = df_x.groupby([\n",
    "    'simulation',\n",
    "])['xt'].shift(1)\n",
    "df_x['_delta_x'] = (df_x['xt'] - df_x['_delta_x'])\n",
    "df_x.loc[df_x._delta_x.isna(), '_delta_x'] = 0.\n",
    "# Sort to get the examples in blocks\n",
    "df_x.sort_values(\n",
    "    [\n",
    "        'simulation',\n",
    "        'dt'\n",
    "    ],\n",
    "    inplace = True\n",
    ")\n",
    "# Adjust x\n",
    "mc_paths_tranformed = df_x[['xt', 'dt']].values.astype(np.float64)\n",
    "delta_x = df_x._delta_x.values.astype(np.float64)\n",
    "# mc_paths_tranformed = np.reshape(mc_paths_tranformed, (N_steps * nsims, 2)).T\n",
    "# Data used as features\n",
    "x = mc_paths_tranformed.astype(np.float64)\n",
    "x = tf.constant(x)\n",
    "v_lgm_single_step, predictions = lgm_single_step.predict(x, \n",
    "                                                         delta_x,\n",
    "                                                         build_masks = True)\n",
    "# Adapt output\n",
    "results = pd.DataFrame(\n",
    "    zip(v_lgm_single_step),\n",
    "    columns = ['results']\n",
    ")\n",
    "v_lgm_single_step = results.explode('results').values\n",
    "df_x['lgm_single_step_V'] = v_lgm_single_step.astype(np.float64)\n",
    "v_df = pd.DataFrame(\n",
    "    zip(df_x.lgm_single_step_V.values,\n",
    "        df_x.dt.values, \n",
    "        df_x.xt.values,\n",
    "        df_x.simulation.values), \n",
    "    columns = ['V_hat_single_step', \n",
    "               'deltat', \n",
    "               'xt',\n",
    "               'simulation']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.lineplot(\n",
    "    x = 'deltat',\n",
    "    y = 'V_hat_single_step',\n",
    "    color = 'blue',\n",
    "    hue = 'simulation',\n",
    "    data = v_df\n",
    ")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils.utils import FinanceUtils\n",
    "# Calcule cts\n",
    "t_unique = v_df.deltat.unique()\n",
    "dict_C = {dt:FinanceUtils.C(dt, sigma_value = sigma) for dt in t_unique}\n",
    "v_df['ct'] = v_df.apply(lambda x: dict_C[x['deltat']], axis = 1)\n",
    "v_df.head()\n",
    "# Value IRS\n",
    "n_sims_test = int(v_df.shape[0] / N_steps)\n",
    "x_reformat = tf.reshape(v_df.xt, (n_sims_test, N_steps))\n",
    "xn_tensor = x_reformat[:, -1]\n",
    "\n",
    "c_reformat = tf.reshape(v_df.ct, (n_sims_test, N_steps))\n",
    "c_tensor = c_reformat[:, -1]\n",
    "print(f'IRS value: {IRS.IRS_normalized(xn_tensor, np.float64(T), 2 * np.float64(T), c_tensor)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b391e97e35ec4987120a2f780cd64183fdb56c026e5a7e01d3347b3d6528b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
